{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeoExploreTech/APP_BACKEND_NODEJS/blob/master/IFC_2_CITYJSON_GEOM_SETTING_TOPO_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and set up Conda in Google Colab using condacolab"
      ],
      "metadata": {
        "id": "LLGcKwbgLV-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUFhUGfa6gXo",
        "outputId": "1c6ee824-dce0-439e-8d35-e5fa0dd1e5e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:12\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a summarized comment for your code:  \n",
        "\n",
        "```python\n",
        "# Create a Conda environment with Python 3.10, activate it, and install required packages:\n",
        "# - pythonocc-core (version 7.8.1.1) from conda-forge\n",
        "# - pandas, lark, ifcopenshell, and pythreejs\n",
        "!conda create --name=pyoccenv python=3.10\n",
        "!source activate pyoccenv\n",
        "!conda install -c conda-forge pythonocc-core=7.8.1.1\n",
        "!conda install pandas lark ifcopenshell pythreejs\n",
        "```\n",
        "\n",
        "### Note:\n",
        "- The `!source activate pyoccenv` command might need adjustment in some systems or scripts (e.g., using `conda activate pyoccenv` depending on the shell)."
      ],
      "metadata": {
        "id": "I8KnrgIWL_H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create --name=pyoccenv python=3.10\n",
        "!source activate pyoccenv\n",
        "!conda install -c conda-forge pythonocc-core=7.8.1.1\n",
        "!conda install pandas lark ifcopenshell pythreejs"
      ],
      "metadata": {
        "id": "0zRSBZ3G6zHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kvB_Gv11EeOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0iz1SiQ6NH13"
      },
      "outputs": [],
      "source": [
        "# Import necessary library\n",
        "import ifcopenshell\n",
        "import ifcopenshell.geom\n",
        "import ifcopenshell.util.element\n",
        "import ifcopenshell.util.shape\n",
        "from OCC.Display.WebGl.jupyter_renderer import JupyterRenderer, format_color\n",
        "\n",
        "from OCC.Core.TopoDS import TopoDS_Compound, TopoDS_Solid, TopoDS_Shell, TopoDS_Face, topods\n",
        "from OCC.Core.TopExp import TopExp_Explorer\n",
        "from OCC.Core.BRepCheck import BRepCheck_Analyzer\n",
        "from OCC.Core.BRep import BRep_Tool\n",
        "from OCC.Core.TopAbs import TopAbs_VERTEX, TopAbs_FACE,TopAbs_ShapeEnum\n",
        "from OCC.Core.gp import gp_Pnt\n",
        "from OCC.Core.BRepMesh import BRepMesh_IncrementalMesh\n",
        "\n",
        "\n",
        "import uuid\n",
        "import json\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "from scipy.optimize import least_squares\n",
        "\n",
        "import shapely\n",
        "from shapely.geometry import MultiPolygon, Polygon\n",
        "from shapely.ops import unary_union\n",
        "from shapely.validation import make_valid\n",
        "\n",
        "import math\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function, get_ifc_model, is a simple utility to load an IFC model using the Ifcopenshell library. Here's a concise explanation as a comment:"
      ],
      "metadata": {
        "id": "Fo3-bIahMkAU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V7S-zN3T9rBT"
      },
      "outputs": [],
      "source": [
        "# IFC file uploaded to IFC_Model\n",
        "def get_ifc_model(ifc_file_name):\n",
        "    \"\"\"Get the IFC model from the uploaded file.\"\"\"\n",
        "    return ifcopenshell.open(ifc_file_name)  # Open the IFC file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a concise explanation of the `extract_a_space_semantics` function as a comment:\n",
        "\n",
        "```python\n",
        "def extract_a_space_semantics(element):\n",
        "    \"\"\"\n",
        "    Extract semantic information from a specific IfcSpace element.\n",
        "\n",
        "    Returns a dictionary with:\n",
        "    - \"id\": Global ID of the element.\n",
        "    - \"type\": IFC type of the element.\n",
        "    - \"name\": Name of the element (defaults to \"Unnamed\" if not set).\n",
        "    - \"attributes\": Dictionary of property names and their values.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"id\": element.GlobalId,\n",
        "        \"type\": element.is_a(),\n",
        "        \"name\": element.Name if element.Name else \"Unnamed\",\n",
        "        \"attributes\": {\n",
        "            prop.Name: prop.NominalValue.wrappedValue if hasattr(prop.NominalValue, 'wrappedValue') else prop.NominalValue\n",
        "            for prop in element.IsDefinedBy[0].RelatingPropertyDefinition.HasProperties\n",
        "            if hasattr(element, 'IsDefinedBy') and element.IsDefinedBy\n",
        "        }\n",
        "    }\n",
        "```\n",
        "### Key Points:\n",
        "1. **Input:** The function takes an IFC element (e.g., `IfcSpace`) as input.\n",
        "2. **Output:** A dictionary containing:\n",
        "   - **Global ID:** A unique identifier for the element.\n",
        "   - **IFC Type:** The type of the element (e.g., `IfcSpace`).\n",
        "   - **Name:** The name of the element, with \"Unnamed\" as a fallback.\n",
        "   - **Attributes:** A dictionary of property names and values from the element's associated property definitions.  \n",
        "3. **Error Handling:** The function uses checks (`hasattr`) to ensure it only accesses valid attributes, avoiding errors on missing properties."
      ],
      "metadata": {
        "id": "Mxw4UYKmM76g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Extracting Semantics Model from Space\n",
        "def extract_a_space_semantics(element):\n",
        "    \"\"\"Extract semantics from the IFC from a particular IfcSpace element\"\"\"\n",
        "\n",
        "    return {\n",
        "        \"id\": element.GlobalId,\n",
        "        \"type\": element.is_a(),\n",
        "        \"name\": element.Name if element.Name else \"Unnamed\",\n",
        "        \"attributes\": {prop.Name: prop.NominalValue.wrappedValue if hasattr(prop.NominalValue, 'wrappedValue') else prop.NominalValue\n",
        "                        for prop in element.IsDefinedBy[0].RelatingPropertyDefinition.HasProperties\n",
        "                        if hasattr(element, 'IsDefinedBy') and element.IsDefinedBy}\n",
        "    }\n"
      ],
      "metadata": {
        "id": "84JE1heM8W_Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_string_value(data):\n",
        "  \"\"\"\n",
        "  Extracts the string value enclosed within IfcIdentifier, IfcLabel, or IfcText\n",
        "  from a given dictionary.\n",
        "\n",
        "  Args:\n",
        "    data: The dictionary object containing the data.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary containing the extracted string values.\n",
        "  \"\"\"\n",
        "\n",
        "  extracted_values = {}\n",
        "  pattern = r\"Ifc(Identifier|Label|Text)\\('(.*?)'\\)\"\n",
        "\n",
        "  for key, value in data.items():\n",
        "    if value:\n",
        "      # Convert value to string before applying regex\n",
        "      try:\n",
        "        value_str = str(value)\n",
        "      except:\n",
        "        value_str = \"\" # Handle cases where conversion to string might fail\n",
        "\n",
        "      match = re.search(pattern, value_str)\n",
        "      if match:\n",
        "        extracted_values[key] = match.group(2)\n",
        "\n",
        "  return extracted_values"
      ],
      "metadata": {
        "id": "ViOh5PH7ocbA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Extracting Zones Attribute from IFC file\n",
        "def get_ifc_zone_attributes_per_one(zone):\n",
        "    \"\"\"\n",
        "    Extracts and prints all semantic attributes and custom properties from IfcZone entities in an IFC file.\n",
        "\n",
        "    Args:\n",
        "        zone (element): IfcZone element.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are IfcZone names and values are dictionaries of attributes and custom properties.\n",
        "    \"\"\"\n",
        "\n",
        "    zone_data = {}\n",
        "\n",
        "    # Extract standard attributes\n",
        "    for attr_name in dir(zone):\n",
        "        if not attr_name.startswith(\"__\") and not callable(getattr(zone, attr_name)):\n",
        "            zone_data[attr_name] = getattr(zone, attr_name)\n",
        "\n",
        "    # Extract custom properties\n",
        "    custom_properties = {}\n",
        "    for rel in zone.IsDefinedBy:\n",
        "        if rel.is_a(\"IfcRelDefinesByProperties\"):\n",
        "            prop_set = rel.RelatingPropertyDefinition\n",
        "            if prop_set.is_a(\"IfcPropertySet\"):\n",
        "                for prop in prop_set.HasProperties:\n",
        "                    if prop.Name != \"Type\":\n",
        "                        custom_properties[prop.Name] = getattr(prop, \"NominalValue\", None)\n",
        "\n",
        "\n",
        "    # Add custom properties to the data\n",
        "    zone_data[\"CustomProperties\"] = extract_string_value(custom_properties)\n",
        "\n",
        "    return zone_data"
      ],
      "metadata": {
        "id": "ALCjm6uR9TNQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the shape is valid\n",
        "def is_valid_shape(shape):\n",
        "    analyzer = BRepCheck_Analyzer(shape)\n",
        "    return analyzer.IsValid()"
      ],
      "metadata": {
        "id": "aR9WLC96aHk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get faces from TopoDS_Compound or TopoDS_Shell\n",
        "def get_faces(shape):\n",
        "    faces = []\n",
        "    if isinstance(shape, TopoDS_Compound):\n",
        "        explorer = TopExp_Explorer(shape, TopAbs_FACE) # Use TopAbs_FACE instead of TopoDS_Face\n",
        "        while explorer.More():\n",
        "            face = explorer.Current()\n",
        "            faces.append(face)\n",
        "            explorer.Next()\n",
        "    elif isinstance(shape, (TopoDS_Solid, TopoDS_Shell)):\n",
        "        explorer = TopExp_Explorer(shape, TopAbs_FACE) # Use TopAbs_FACE instead of TopoDS_Face\n",
        "        while explorer.More():\n",
        "            face = explorer.Current()\n",
        "            faces.append(face)\n",
        "            explorer.Next()\n",
        "    elif isinstance(shape, TopoDS_Face):\n",
        "        faces.append(shape)\n",
        "    return faces"
      ],
      "metadata": {
        "id": "fZ-ly0jsg0wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vertices(face):\n",
        "    vertices = []\n",
        "    explorer = TopExp_Explorer(face, TopAbs_VERTEX)\n",
        "    while explorer.More():\n",
        "        vertex = explorer.Current()\n",
        "        point = BRep_Tool.Pnt(vertex)\n",
        "        vertices.append((point.X(), point.Y(), point.Z()))\n",
        "        explorer.Next()\n",
        "    return vertices"
      ],
      "metadata": {
        "id": "ZunIfSaTinge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cityjson_with_attribute_data(ifc_file_model:ifcopenshell):\n",
        "\n",
        "    settings = ifcopenshell.geom.settings()\n",
        "    settings.set(settings.USE_WORLD_COORDS, True)\n",
        "    settings.set(settings.USE_PYTHON_OPENCASCADE, True)\n",
        "\n",
        "\n",
        "    cityjson = {\n",
        "        \"type\": \"CityJSON\",\n",
        "        \"version\": \"2.0\",  # Or your desired version\n",
        "        \"CityObjects\": {},\n",
        "        \"vertices\": [],\n",
        "        \"transform\": {\n",
        "            \"scale\": [1.0, 1.0, 1.0], # Default scaling\n",
        "            \"translate\": [0.0, 0.0, 0.0] # Default translation\n",
        "        },\n",
        "      \"metadata\": {\n",
        "        \"referenceSystem\": \"\"\n",
        "      },\n",
        "    }\n",
        "\n",
        "    vertex_index = 0\n",
        "\n",
        "    # Retrieve all IfcZone entities\n",
        "    ifc_zones = ifc_file_model.by_type(\"IfcZone\")\n",
        "\n",
        "    # Iterate through all zone element\n",
        "    for zone in ifc_zones:\n",
        "\n",
        "        zone_data = get_ifc_zone_attributes_per_one(zone)\n",
        "        zone_info = {\n",
        "            \"ZoneName\": zone_data[\"Name\"],\n",
        "            \"ZoneDetails\":{**zone_data[\"CustomProperties\"]}\n",
        "            }\n",
        "\n",
        "\n",
        "        for rel in zone.IsGroupedBy:\n",
        "            if rel.is_a(\"IfcRelAssignsToGroup\"):\n",
        "                for space in rel.RelatedObjects:\n",
        "                    if space.is_a(\"IfcSpace\"):\n",
        "                        # print(space.Name)\n",
        "                        space_info = extract_a_space_semantics(space)\n",
        "                        space_detail = {**space_info[\"attributes\"]}\n",
        "                        space_attributes = {\n",
        "                            \"SpaceName\": space_info[\"name\"],\n",
        "                            }\n",
        "                        # print(space_info)\n",
        "                        if space.Representation is not None:\n",
        "                            shape = ifcopenshell.geom.create_shape(settings, space)\n",
        "                            geometry = shape.geometry\n",
        "                            if not is_valid_shape(geometry):\n",
        "                                print(\"Invalid geometry. Skipping...\")\n",
        "                            else:\n",
        "                                # print(geometry)\n",
        "                                faces = get_faces(geometry)\n",
        "\n",
        "                            if faces:\n",
        "                                space_id = space.GlobalId\n",
        "                                # cityjson[\"CityObjects\"][zone.GlobalId][\"members\"].append(space_id)\n",
        "                                cityjson[\"CityObjects\"][space_id] = {\n",
        "                                    \"type\": \"Building\",\n",
        "                                    \"attributes\": {**zone_info, **space_attributes,**space_detail},\n",
        "                                    \"geometry\": [{\n",
        "                                        \"type\": \"Solid\",\n",
        "                                        \"lod\": \"2\",\n",
        "                                        \"boundaries\": []\n",
        "                                    }]\n",
        "                                }\n",
        "\n",
        "                                boundaries = []\n",
        "                                for face in faces:\n",
        "                                    face_vertices = get_vertices(face)\n",
        "                                    boundary = []\n",
        "                                    for vertex in face_vertices:\n",
        "                                        if vertex not in cityjson[\"vertices\"]:\n",
        "                                            cityjson[\"vertices\"].append(vertex)\n",
        "                                        vertex_index = cityjson[\"vertices\"].index(vertex)\n",
        "                                        boundary.append(vertex_index)\n",
        "                                    boundaries.append([boundary]) # Double list for CityJSON\n",
        "                                cityjson[\"CityObjects\"][space_id][\"geometry\"][0][\"boundaries\"].append(boundaries)\n",
        "\n",
        "    return cityjson\n"
      ],
      "metadata": {
        "id": "jLrygZ7x-vs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_city_bounding_box_points(cityjson_file):\n",
        "    \"\"\"\n",
        "    Extract the bounding box of all city objects combined as a list of points.\n",
        "\n",
        "    Args:\n",
        "        cityjson_file (str): Path to the CityJSON file.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of (x, y, z) tuples representing the bounding box points.\n",
        "    \"\"\"\n",
        "    with open(cityjson_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Fetch vertices from CityJSON file\n",
        "    vertices = data.get(\"vertices\", [])\n",
        "\n",
        "    if not vertices:\n",
        "        raise ValueError(\"No vertices found in the CityJSON file.\")\n",
        "\n",
        "    # Calculate bounding box\n",
        "    min_x = min(v[0] for v in vertices)\n",
        "    min_y = min(v[1] for v in vertices)\n",
        "    min_z = min(v[2] for v in vertices)\n",
        "\n",
        "    max_x = max(v[0] for v in vertices)\n",
        "    max_y = max(v[1] for v in vertices)\n",
        "    max_z = max(v[2] for v in vertices)\n",
        "\n",
        "    # Create a list of points representing the 3D bounding box\n",
        "    bounding_box_points = [\n",
        "        (min_x, min_y, min_z),\n",
        "        (min_x, max_y, min_z),\n",
        "        (max_x, max_y, min_z),\n",
        "        (max_x, min_y, min_z),\n",
        "        (min_x, min_y, min_z),  # Close the polygon\n",
        "        (min_x, min_y, max_z),\n",
        "        (min_x, max_y, max_z),\n",
        "        (max_x, max_y, max_z),\n",
        "        (max_x, min_y, max_z),\n",
        "        (min_x, min_y, max_z)  # Close the upper polygon\n",
        "    ]\n",
        "\n",
        "    return bounding_box_points\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S6Lz02eBdJkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)  # for reproducibility\n",
        "\n",
        "def compute_transformation_params(local_coords, global_coords):\n",
        "    \"\"\"\n",
        "    Computes transformation parameters (scale, rotation, translation)\n",
        "    for converting from a local coordinate system to a global coordinate system.\n",
        "\n",
        "    Args:\n",
        "        local_coords (numpy.ndarray): Array of local coordinates (Nx2).\n",
        "        global_coords (numpy.ndarray): Array of corresponding global coordinates (Nx2).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - scale (float): Scale factor.\n",
        "            - rotation (float): Rotation angle in radians (counter-clockwise).\n",
        "            - translation (numpy.ndarray): Translation vector (1x2).\n",
        "            Returns None if the input data is invalid.\n",
        "        Raises:\n",
        "            ValueError: If the input arrays have incompatible shapes or if there are insufficient points.\n",
        "    \"\"\"\n",
        "\n",
        "    local_coords = np.asarray(local_coords)\n",
        "    global_coords = np.asarray(global_coords)\n",
        "\n",
        "    if local_coords.shape != global_coords.shape or local_coords.shape[1] != 2:\n",
        "        raise ValueError(\"Input coordinate arrays must have the same shape (Nx2).\")\n",
        "\n",
        "    n_points = local_coords.shape[0]\n",
        "    if n_points < 2:  # Need at least 2 points for affine transformation\n",
        "        raise ValueError(\"At least two corresponding points are required for transformation.\")\n",
        "\n",
        "    # Calculate centroids\n",
        "    local_centroid = np.mean(local_coords, axis=0)\n",
        "    global_centroid = np.mean(global_coords, axis=0)\n",
        "\n",
        "    # Center the coordinates\n",
        "    local_centered = local_coords - local_centroid\n",
        "    global_centered = global_coords - global_centroid\n",
        "\n",
        "    # Calculate the covariance matrix\n",
        "    covariance_matrix = np.dot(global_centered.T, local_centered)\n",
        "\n",
        "    # Calculate the singular value decomposition (SVD)\n",
        "    U, S, V = np.linalg.svd(covariance_matrix)\n",
        "\n",
        "    # Calculate the rotation matrix\n",
        "    rotation_matrix = np.dot(U, V)\n",
        "\n",
        "    # Handle reflection case (if det(rotation_matrix) < 0)\n",
        "    if np.linalg.det(rotation_matrix) < 0:\n",
        "        V[1, :] *= -1  # Flip the sign of the last row of V\n",
        "        rotation_matrix = np.dot(U, V)\n",
        "\n",
        "    # Calculate the rotation angle (in radians)\n",
        "    rotation = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
        "\n",
        "    # Calculate the scale factor\n",
        "    scale = np.mean(np.linalg.norm(global_centered, axis=1) / np.linalg.norm(local_centered, axis=1))\n",
        "\n",
        "    # Calculate the translation vector\n",
        "    translation = global_centroid - scale * np.dot(local_centroid, rotation_matrix)\n",
        "\n",
        "    return scale, rotation, translation\n",
        "\n",
        "\n",
        "def test_transformation_accuracy(local_coords, global_coords, tolerance=1e-6):\n",
        "    \"\"\"\n",
        "    Tests the accuracy of the transformation by comparing the transformed local coordinates\n",
        "    to the original global coordinates.\n",
        "\n",
        "    Args:\n",
        "        local_coords (numpy.ndarray): Array of local coordinates (Nx2).\n",
        "        global_coords (numpy.ndarray): Array of corresponding global coordinates (Nx2).\n",
        "        tolerance (float): Tolerance for comparing coordinates (default: 1e-6).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - rmse (float): Root Mean Square Error of the transformation.\n",
        "            - max_error (float): Maximum absolute error of the transformation.\n",
        "            - success (bool): True if all transformed coordinates are within the tolerance, False otherwise.\n",
        "        Raises:\n",
        "            ValueError: If the input arrays have incompatible shapes.\n",
        "    \"\"\"\n",
        "\n",
        "    local_coords = np.asarray(local_coords)\n",
        "    global_coords = np.asarray(global_coords)\n",
        "\n",
        "    if local_coords.shape != global_coords.shape or local_coords.shape[1] != 2:\n",
        "        raise ValueError(\"Input coordinate arrays must have the same shape (Nx2).\")\n",
        "\n",
        "    try:\n",
        "        scale, rotation, translation = compute_transformation_params(local_coords, global_coords)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during transformation parameter computation: {e}\")\n",
        "        return float('inf'), float('inf'), False  # Return infinite error if transformation fails\n",
        "\n",
        "    # Apply the transformation\n",
        "    rotation_matrix = np.array([[np.cos(rotation), -np.sin(rotation)], [np.sin(rotation), np.cos(rotation)]])\n",
        "    transformed_coords = scale * np.dot(local_coords, rotation_matrix) + translation\n",
        "\n",
        "    # Calculate errors\n",
        "    errors = np.linalg.norm(transformed_coords - global_coords, axis=1)\n",
        "    rmse = np.sqrt(np.mean(errors**2))\n",
        "    max_error = np.max(errors)\n",
        "    success = np.all(errors <= tolerance)\n",
        "\n",
        "    return rmse, max_error, success\n",
        "\n",
        "import math\n",
        "\n",
        "def compute_transformation_params_least_squares(local_coords, global_coords):\n",
        "    \"\"\"\n",
        "    Computes transformation parameters (scale, rotation, translation) using least squares adjustment.\n",
        "\n",
        "    Args:\n",
        "        local_coords (numpy.ndarray): Array of local coordinates (Nx2).\n",
        "        global_coords (numpy.ndarray): Array of corresponding global coordinates (Nx2).\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - scale (float): Scale factor.\n",
        "            - rotation (float): Rotation angle in radians.\n",
        "            - translation (numpy.ndarray): Translation vector (1x2).\n",
        "            Returns None if the input data is invalid.\n",
        "        Raises:\n",
        "            ValueError: If the input arrays have incompatible shapes or if there are insufficient points.\n",
        "    \"\"\"\n",
        "\n",
        "    local_coords = np.asarray(local_coords)\n",
        "    global_coords = np.asarray(global_coords)\n",
        "\n",
        "    if local_coords.shape != global_coords.shape or local_coords.shape[1] != 2:\n",
        "        raise ValueError(\"Input coordinate arrays must have the same shape (Nx2).\")\n",
        "\n",
        "    n_points = local_coords.shape[0]\n",
        "    if n_points < 2:  # Need at least 2 points for affine transformation\n",
        "        raise ValueError(\"At least two corresponding points are required for transformation.\")\n",
        "\n",
        "    # Construct the design matrix A and the observation vector l\n",
        "    A = np.zeros((2 * n_points, 4))\n",
        "    l = global_coords.flatten()\n",
        "\n",
        "    for i in range(n_points):\n",
        "        A[2 * i, 0] = local_coords[i, 0]\n",
        "        A[2 * i, 1] = -local_coords[i, 1]\n",
        "        A[2 * i, 2] = 1\n",
        "        A[2 * i + 1, 0] = local_coords[i, 1]\n",
        "        A[2 * i + 1, 1] = local_coords[i, 0]\n",
        "        A[2 * i + 1, 3] = 1\n",
        "\n",
        "    # Least squares solution: x = (A^T * A)^-1 * A^T * l\n",
        "    try:\n",
        "        x = np.linalg.solve(A.T @ A, A.T @ l)\n",
        "    except np.linalg.LinAlgError:\n",
        "        print(\"Singular matrix encountered. Least squares solution could not be computed.\")\n",
        "        return None\n",
        "\n",
        "    # Extract the transformation parameters\n",
        "    scale = np.sqrt(x[0]**2 + x[1]**2)\n",
        "    rotation = np.arctan2(x[1], x[0])\n",
        "    translation = np.array([x[2], x[3]])\n",
        "\n",
        "    return scale, rotation, translation\n",
        "\n",
        "def transform_coordinates(local_coords, scale, rotation, translation):\n",
        "    \"\"\"\n",
        "    Transforms local coordinates to global coordinates using given transformation parameters.\n",
        "\n",
        "    Args:\n",
        "        local_coords (numpy.ndarray): Array of local coordinates (Nx2).\n",
        "        scale (float): Scale factor.\n",
        "        rotation (float): Rotation angle in radians.\n",
        "        translation (numpy.ndarray or list): Translation vector (1x2).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Array of transformed (global) coordinates (Nx2).\n",
        "        Raises:\n",
        "            ValueError: If the input arrays have incompatible shapes.\n",
        "    \"\"\"\n",
        "    local_coords = np.asarray(local_coords)\n",
        "    translation = np.asarray(translation)\n",
        "\n",
        "    if local_coords.ndim != 2 or local_coords.shape[1] != 2:\n",
        "      raise ValueError(\"Local coordinates must be a Nx2 array.\")\n",
        "    if translation.shape != (2,):\n",
        "      raise ValueError(\"Translation must be a 1x2 array or list.\")\n",
        "\n",
        "    rotation_matrix = np.array([[np.cos(rotation), -np.sin(rotation)],\n",
        "                                [np.sin(rotation), np.cos(rotation)]])\n",
        "\n",
        "    transformed_coords = scale * np.dot(local_coords, rotation_matrix) + translation\n",
        "\n",
        "    return transformed_coords\n"
      ],
      "metadata": {
        "id": "kQbqp7l5MZ_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_cityjson(file_path, output_path, scale, rotation, translation, epsg):\n",
        "    \"\"\"\n",
        "    Transform the vertices of a CityJSON file using Helmert 7-Parameter Transformation.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the input CityJSON file.\n",
        "        output_path: Path to save the transformed CityJSON file.\n",
        "        params: Dictionary containing the Helmert parameters.\n",
        "    \"\"\"\n",
        "    # Load CityJSON file\n",
        "    with open(file_path, 'r') as f:\n",
        "        cityjson = json.load(f)\n",
        "    # Adding reference system\n",
        "    cityjson[\"metadata\"][\"referenceSystem\"] = f\"https://www.opengis.net/def/crs/EPSG/0/{epsg}\"\n",
        "\n",
        "    # Transform all vertices\n",
        "    for i, vertex in enumerate(cityjson['vertices']):\n",
        "        X, Y, Z = vertex\n",
        "        local_coords_test = np.array([[X, Y]])\n",
        "        transformed_coords = transform_coordinates(local_coords_test, scale, rotation, translation)[0]\n",
        "        # X_prime, Y_prime, Z_prime = helmert_transformation(X, Y, Z, params)\n",
        "        cityjson['vertices'][i] = [transformed_coords[0], transformed_coords[1], Z]\n",
        "\n",
        "    # Save transformed CityJSON file\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(cityjson, f, indent=2)\n",
        "    print(f\"Transformed CityJSON saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "UoIlcGWE8NGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the IFC file\n",
        "ifc_file_name = \"/content/bally-ifc.ifc\"  # Get the name of the uploade\n",
        "ifcModel = get_ifc_model(ifc_file_name)\n",
        "\n",
        "cityjson_data = create_cityjson_with_attribute_data(ifcModel)\n",
        "\n",
        "# print(cityjson_data)\n",
        "with open(\"output_no_georefrence.json\", \"w\") as outfile:\n",
        "    json.dump(cityjson_data, outfile, indent=4)\n",
        "\n",
        "print(\"CityJSON file created successfully!\")\n",
        "# json_result = json.dumps(semanticData, indent=4, default=str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNMysYs2p4ch",
        "outputId": "f0ae46ba-5dad-4f3f-c86c-94c854b91784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CityJSON file created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "boundary = extract_city_bounding_box_points(\"/content/output_no_georefrence.json\")\n",
        "json_result = json.dumps(boundary, indent=4, default=str)\n",
        "print(json_result)"
      ],
      "metadata": {
        "id": "DCqZKm8igZcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the coordinate transformation parameters\n",
        "local_coords = np.array([\n",
        "    [0.115,-3.20944193],\n",
        "    [0.11500000,11.90803589],\n",
        "    [59.42595128,11.90803589],\n",
        "    [59.42595128,-3.20944193]\n",
        "])\n",
        "local_coords_test = np.array([\n",
        "    [0.115,5]\n",
        "\n",
        "])\n",
        "global_coords = np.array([\n",
        "    [333337.4405,999661.4498],\n",
        "    [333324.3872,999653.8241],\n",
        "    [333294.4690,999705.0363],\n",
        "    [333307.5222,999712.6620]\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "scale, rotation, translation = compute_transformation_params_least_squares(local_coords, global_coords)\n",
        "\n",
        "print(\"Scale:\", scale)\n",
        "print(\"Rotation (radians):\", rotation)\n",
        "print(\"Translation:\", translation)\n",
        "\n",
        "#     # Test the transformation\n",
        "#     transformed_coords = scale * np.dot(local_coords, np.array([[np.cos(rotation), -np.sin(rotation)], [np.sin(rotation), np.cos(rotation)]])) + translation\n",
        "#     print(\"Transformed coordinates:\\n\", transformed_coords)\n",
        "#     print(\"Original global coordinates:\\n\", global_coords)\n",
        "\n",
        "#     # Test accuracy\n",
        "#     rmse, max_error, success = test_transformation_accuracy(local_coords, global_coords)\n",
        "#     print(\"RMSE:\", rmse)\n",
        "#     print(\"Maximum Error:\", max_error)\n",
        "#     print(\"Success:\", success)\n",
        "\n",
        "#     transformed_coords2 = transform_coordinates(local_coords_test, scale, rotation, translation)\n",
        "#     print(\"Transformed coordinates 2:\\n\", transformed_coords2[0])\n",
        "\n",
        "# except ValueError as e:\n",
        "#     print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go7LeLCiToyq",
        "outputId": "27855286-9a1e-4ca2-ede7-186652a9d0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scale: 1.0000003564278797\n",
            "Rotation (radians): 2.0995182646239856\n",
            "Translation: [333334.72727011 999659.73156771]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input and output file paths\n",
        "input_file = \"/content/output_no_georefrence.json\"\n",
        "output_file = \"citymodel_transformed.json\"\n",
        "\n",
        "# Transform the CityJSON file\n",
        "transform_cityjson(input_file, output_file, scale, rotation, translation, 32632)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RFMDNIH8y7O",
        "outputId": "04b97c2f-f66f-46f3-eb9c-c4b30787a3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed CityJSON saved to: citymodel_transformed.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}